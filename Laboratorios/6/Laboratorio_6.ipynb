{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbnqmEMV9ksq"
      },
      "source": [
        "# `Laboratorio 6 | Machine Learning`\n",
        "* Marco Ferraro | B82957\n",
        "* Roy Padilla | B85854"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fhum9aL-7pR"
      },
      "source": [
        "Descarga del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFPLbAUp9ayJ"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torch\n",
        "\n",
        "\n",
        "CLASSIFIER_LR = 5e-3\n",
        "CLASSIFIER_THRESHOLD = 0.9\n",
        "CLASSIFIER_EPOCHS = 400\n",
        "\n",
        "GEN_LR = 6e-4\n",
        "NORMALIZER_RESCALE_GRAY = 255\n",
        "GEN_MOMENTUM = 1e-6\n",
        "GEN_INPUT_DIM = 350\n",
        "GEN_EPOCHS = 450\n",
        "GEN_DECAY = 7e-3\n",
        "\n",
        "GAN_EPOCH = 50\n",
        "EPOCH = 100\n",
        "\n",
        "# Descarga del set de datos\n",
        "train = torchvision.datasets.MNIST(\".\", download=True)\n",
        "\n",
        "# Extracción de datos\n",
        "x = (train.data.to(torch.uint8)/NORMALIZER_RESCALE_GRAY).float()\n",
        "y = train.targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVAg697CLshO"
      },
      "source": [
        "Clase para manejar el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNQhTaJXLshO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class Dset(torch.utils.data.Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.n_samples = x.shape[0]\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.n_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5qPR6CqLshP"
      },
      "source": [
        "Pruebas de mostrado de imágenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u6RwjGiLshP"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch import flatten\n",
        "\n",
        "def plot_image(img,save=False,name=None):\n",
        "    cmap = 'gray' if img.shape[0]==1 else None\n",
        "    data = (img.detach()*(255 if img.max()<=1 else 1)).permute((1,2,0)).numpy().astype(np.uint8)\n",
        "    plt.figure()\n",
        "    plt.imshow(data,cmap=cmap)\n",
        "    plt.show()\n",
        "    if save:\n",
        "        if img.shape[0]==1:\n",
        "            plt.imsave('data/' + name, data.squeeze(), cmap=cmap)\n",
        "        else:\n",
        "            plt.imsave('data/' + name, data, cmap=cmap)\n",
        "\n",
        "img_number = 0\n",
        "img = x[img_number] * NORMALIZER_RESCALE_GRAY\n",
        "plot_image( img[None, :], True, '{}.png'.format(img_number))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzAhRNeILshQ"
      },
      "source": [
        "Filtrado de las imágenes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LCQ1Fm2LshQ"
      },
      "outputs": [],
      "source": [
        "from torch import nonzero\n",
        "\n",
        "target_number = 8\n",
        "\n",
        "indeces = y == target_number\n",
        "\n",
        "x_true = x[nonzero(indeces)]\n",
        "\n",
        "img_number = 1863\n",
        "img = x_true[img_number]\n",
        "plot_image( img, True, '{}.png'.format(img_number))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe8gknkJLshR"
      },
      "source": [
        "`Clase Classifier`: \n",
        "Se va a encarga de determinar si una imagen es o no perteneciente a un dígito en específico o no"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbkTkAbSLshR"
      },
      "outputs": [],
      "source": [
        "from torch import nn, flatten, tensor, cat, device, ones, zeros\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "DEVICE = device(\"cuda:0\")\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Primera convolución\n",
        "        # Entra una imagen 1x28x28\n",
        "        self.conv1 =  nn.Conv2d(in_channels = 1, out_channels = 4, kernel_size = (5,5), stride = 1, padding = 'same')\n",
        "        # Sale una imagen de 4x28x28\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.maxpool1 = nn.MaxPool2d(2)\n",
        "        # img de 4x14x14 => 784\n",
        "\n",
        "        # # Entra una imagen 4x14x14 => 784\n",
        "        self.conv2 =  nn.Conv2d(in_channels = 4, out_channels = 10, kernel_size = (3,3), stride = 1, padding = 'same')\n",
        "        # # Sale una imagen de 10x14x14\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.maxpool2 = nn.MaxPool2d(2)\n",
        "\n",
        "        # img de 10x7x7 => 490\n",
        "        # Red neuronal\n",
        "        self.fc1 = nn.Linear(490, 800)\n",
        "        self.act1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(800, 1) # Salida de si es el dígito o no => 1 = Verdadera | 0 = Falso\n",
        "        self.act2 = nn.Sigmoid()\n",
        "\n",
        "        # Dropout (opcional)\n",
        "        self.dropout = nn.Dropout(p = 0.2)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        ''' \n",
        "            Sobre-escritura del método de forward propagation, aplicando las capas convolucionales\n",
        "            y luego las capas densas de la red neuronal\n",
        "        '''\n",
        "        # Aplicación de las convoluciones\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.maxpool1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "        x = flatten(x, 1)\n",
        "\n",
        "        # Capas densas\n",
        "        x = self.act1(self.fc1(x))\n",
        "        out = self.act2(self.fc2(x))\n",
        "\n",
        "        return out\n",
        "\n",
        "    \n",
        "def train_classifier(opt, model, x_true, x_false, accuracy=None, max_iter=100, batch_size=1000, plot = True):\n",
        "    '''\n",
        "        Método de entrenamiento del clasificador donde se toma el conjunto x de imágenes verdades\n",
        "        y el conjunto de imágenes falsas generadas por el generador para que determine si es o no\n",
        "        el dígito objetivo.\n",
        "        Este asume que le llegan los x divididos por 255 => img_i = [0,1]\n",
        "    '''\n",
        "    iter_counter = 0\n",
        "    model_accuracy = 0\n",
        "    finish_by_accuracy = False\n",
        "    loss_func = nn.BCELoss() # Binary Cross Entropy\n",
        "\n",
        "    losses = []\n",
        "    accuracies = []\n",
        "    while (iter_counter < max_iter and not(finish_by_accuracy)):\n",
        "        iter_loss = []\n",
        "        iter_accuracy = []\n",
        "        # Generación aleatoria de los índices para utilizar en el entrenamiento\n",
        "        true_batch = np.random.randint(0, x_true.shape[0], batch_size)\n",
        "        false_batch = np.random.randint(0, x_false.shape[0], batch_size)\n",
        "\n",
        "        # Obtención del conjunto de entrenamiento\n",
        "        # conjunto para predecir 1\n",
        "        # conjunto para predecir 0\n",
        "        \n",
        "        X_train = cat((x_true[true_batch], x_false[false_batch])).to( device=DEVICE)\n",
        "        y_train = cat((ones(batch_size) , zeros(batch_size))).to( device=DEVICE)\n",
        "\n",
        "        train_dset = Dset(X_train, y_train)\n",
        "        train_loader = DataLoader(dataset= train_dset, batch_size = batch_size, shuffle=True)\n",
        "        # torch.cuda.empty_cache()\n",
        "        # Entrenamiento\n",
        "        model = model.to(DEVICE)\n",
        "        model.train()\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            (inputs, labels) = (inputs.to(DEVICE), labels.to(DEVICE))\n",
        "            y_pred = model( inputs.detach() )\n",
        "            loss = loss_func(y_pred, labels[:, None])\n",
        "            \n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            \n",
        "            y_pred = y_pred > CLASSIFIER_THRESHOLD\n",
        "            iter_loss.append(loss.item())\n",
        "\n",
        "            iter_accuracy.append(accuracy_score(  labels[:, None].cpu() , y_pred.detach().cpu()))\n",
        "        \n",
        "        losses.append( np.array(iter_loss).mean())\n",
        "        model_accuracy = np.array(iter_accuracy).mean()\n",
        "        accuracies.append(model_accuracy)\n",
        "        \n",
        "        finish_by_accuracy = True if accuracy == None else model_accuracy >= accuracy\n",
        "        iter_counter += 1\n",
        "    print('Classifier accuracy', accuracies[-1])\n",
        "    if plot:\n",
        "        model.eval()\n",
        "        y_pred = model(train_dset.x) > CLASSIFIER_THRESHOLD\n",
        "\n",
        "        print(classification_report(train_dset.y.cpu(), y_pred.detach().cpu(), target_names=['Falsa','Real']))\n",
        "        print('Last loss:', losses[-1])\n",
        "            \n",
        "        # Impresión de gráficos y resultados del modelo\n",
        "        len_ = len(losses)\n",
        "        xpoints = np.linspace(0, len_, num = len_)\n",
        "        plt.plot(xpoints, losses)\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title((\"Pérdida del clasificador con {} iteraciones\".format(iter_counter) ))\n",
        "        plt.show()\n",
        "\n",
        "        len_ = len(accuracies)\n",
        "        xpoints = np.linspace(0, len_, num = len_)\n",
        "        plt.plot(xpoints, accuracies)\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.ylabel(\"Accuracy\")\n",
        "        plt.title((\"Accuracy del clasificador con {} iteraciones\".format(iter_counter) ))\n",
        "        plt.show()   \n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwcdQd2cLshS"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim=784):\n",
        "    super(Generator, self).__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "      nn.Linear(input_dim, 512),\n",
        "      nn.Tanh(),\n",
        "      nn.Linear(512, 800),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(800, output_dim),\n",
        "      nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmDqAReFLshT"
      },
      "source": [
        "Generator Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2FnCWDOLshT"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "def train_generator(opt, generator: Generator, classifier: Classifier, accuracy=None, max_iter=10000, batch_size=1000, plot = True):\n",
        "\n",
        "    input_dim = 350\n",
        "    lr = 2e-4\n",
        "\n",
        "    iter_counter = 0\n",
        "    model_accuracy = 0\n",
        "    finish_by_accuracy = False\n",
        "    loss_func = nn.BCELoss() # Binary Cross Entropy\n",
        "    losses = []\n",
        "    accuracies = []\n",
        "    y_train = Variable(torch.ones(batch_size, 1).to(DEVICE))\n",
        "    \n",
        "    while (iter_counter < max_iter and not(finish_by_accuracy)):\n",
        "        generator.zero_grad()\n",
        "        generator.train()\n",
        "      \n",
        "        X_train = Variable(torch.randn(batch_size, input_dim).to(DEVICE))\n",
        "        X_train = X_train.to(torch.uint8)/NORMALIZER_RESCALE_GRAY\n",
        "        generator_output = generator(X_train)\n",
        "        generator_output = generator_output.reshape((batch_size, 1, 28, 28))\n",
        "\n",
        "        \n",
        "        classifier_output = classifier(generator_output)\n",
        "        generator_loss = loss_func(classifier_output, y_train)\n",
        "\n",
        "\n",
        "        generator_loss.backward()\n",
        "        opt.step()\n",
        "        losses.append(generator_loss.item())\n",
        "\n",
        "        classifier_output = classifier_output > CLASSIFIER_THRESHOLD\n",
        "\n",
        "\n",
        "        accuracies.append(accuracy_score(y_train.cpu() , classifier_output.detach().cpu()))\n",
        "        model_accuracy = accuracies[-1]\n",
        "        finish_by_accuracy = True if accuracy == None else model_accuracy >= accuracy\n",
        "        iter_counter += 1\n",
        "        \n",
        "    print('Generator epochs: ', len(accuracies))\n",
        "    if plot:\n",
        "        generator.eval()\n",
        "        generator_output = generator(X_train)\n",
        "        generator_output = generator_output.reshape((batch_size, 1, 28, 28))\n",
        "        classifier_output = classifier(generator_output)\n",
        "        classifier_output = classifier_output > CLASSIFIER_THRESHOLD\n",
        "\n",
        "        print(classification_report(y_train.cpu(), classifier_output.detach().cpu(), target_names=['Falsa','Real'])) if model_accuracy != 1 else print(end=\"\")\n",
        "        print('Last loss:', losses[-1])\n",
        "            \n",
        "        # Impresión de gráficos y resultados del modelo\n",
        "        len_ = len(losses)\n",
        "        xpoints = np.linspace(0, len_, num = len_)\n",
        "        plt.plot(xpoints, losses)\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title((\"Pérdida del generador con {} iteraciones\".format(iter_counter) ))\n",
        "        plt.show()\n",
        "\n",
        "        len_ = len(accuracies)\n",
        "        xpoints = np.linspace(0, len_, num = len_)\n",
        "        plt.plot(xpoints, accuracies)\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.ylabel(\"Accuracy\")\n",
        "        plt.title((\"Accuracy del generador con {} iteraciones\".format(iter_counter) ))\n",
        "        plt.show()   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxX6mIzOLshT"
      },
      "outputs": [],
      "source": [
        "from torch import optim\n",
        "from torch import tensor\n",
        "\n",
        "classifier = Classifier().to(DEVICE)\n",
        "opt_classifier = optim.Adadelta(classifier.parameters(), lr=CLASSIFIER_LR)\n",
        "\n",
        "gen = Generator(input_dim=GEN_INPUT_DIM).to(DEVICE)\n",
        "opt_generator = optim.SGD(gen.parameters(), lr=GEN_LR, momentum=GEN_MOMENTUM, weight_decay= GEN_DECAY)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vkx3EAs4LshT"
      },
      "outputs": [],
      "source": [
        "x_false = torch.randn(x_true.shape[0], GEN_INPUT_DIM).to(DEVICE)\n",
        "x_true = x_true.to(DEVICE)\n",
        "train_classifier(opt=opt_classifier, model = classifier, x_true = x_true, x_false = gen(x_false).reshape(x_true.shape), accuracy = 1, max_iter= 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4ZoNMyHLshU"
      },
      "outputs": [],
      "source": [
        "train_generator(opt=opt_generator, generator=gen, classifier=classifier, accuracy=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28KE5cv0LshU"
      },
      "outputs": [],
      "source": [
        "batch_size = 4000\n",
        "\n",
        "classifier = Classifier().to(DEVICE)\n",
        "opt_classifier = optim.Adadelta(classifier.parameters(), lr=CLASSIFIER_LR)\n",
        "\n",
        "gen = Generator(input_dim=GEN_INPUT_DIM).to(DEVICE)\n",
        "opt_generator = optim.SGD(gen.parameters(), lr=GEN_LR, momentum=GEN_MOMENTUM, weight_decay=GEN_DECAY)\n",
        "\n",
        "for e in range(GAN_EPOCH):\n",
        "  print(\"----------------------------------------------------------------------------\")\n",
        "  print('GAN Epoch:', e)\n",
        "  # Toma aleatoria del set real\n",
        "  true_batch = np.random.randint(0, x_true.shape[0], batch_size)\n",
        "  x_false_batch = torch.randn(x_true.shape[0], GEN_INPUT_DIM).to(DEVICE)\n",
        "  # Entrenamos el generador\n",
        "  train_generator(opt = opt_generator, generator = gen, classifier = classifier, accuracy = 1, plot = False, max_iter= GEN_EPOCHS)\n",
        "  # Entrenamos el clasificador\n",
        "  x_false = gen(x_false_batch).reshape((x_false_batch.shape[0], 1, 28, 28))\n",
        "  img = x_false[np.random.randint(0, x_false.shape[0])]\n",
        "  plot_image( img.cpu(), True, 'epoch_{}.png'.format(e))\n",
        "  train_classifier(opt=opt_classifier, model=classifier, x_true = x_true[true_batch].to(device=DEVICE), x_false = x_false.detach(), accuracy = 1, max_iter= CLASSIFIER_EPOCHS, plot = False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.3 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
