{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbh9Ky3uYw8w"
      },
      "source": [
        "# Laboratorio 4 | Machine Learning\n",
        "* Marco Ferraro | B82957\n",
        "* Roy Padilla | B85854"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIElRyehYw8y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # procesamiento de dataset\n",
        "import math # uso de función exp\n",
        "import numpy as np # uso de funciones y generación de arreglos\n",
        "import math # operación de raíz cuadrada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIojcHgKA8XJ",
        "outputId": "f1d97f2c-ea0d-46d3-b8ec-9e023cda219e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1043, 12)"
            ]
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_value_titanic = ['Survived_0', 'Survived_1']\n",
        "df_titanic = pd.read_csv('titanic.csv')\n",
        "df_titanic = df_titanic.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin']).dropna()\n",
        "\n",
        "# Se pasan a one-hot encoding las columnas 'Pclass','Sex' y 'Survived'\n",
        "df_titanic = pd.get_dummies(df_titanic,columns=['Embarked', 'Pclass','Sex', 'Survived'])\n",
        "y = df_titanic.loc[:, target_value_titanic]\n",
        "\n",
        "\n",
        "df_titanic = df_titanic.drop(columns = target_value_titanic)\n",
        "\n",
        "df_titanic.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p2NcJwCbQXb"
      },
      "source": [
        "1. Función `sigmoid(x)` que recibe un número `x` y retorna el resultado de la función sigmoide para dicho `x:   1/(1 + e^(-x))`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZw1OSmmbVeA"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + math.exp(-x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpO9tpHddsST"
      },
      "source": [
        "2. Función d_sigmoid(y) que recibe un número y (tal que y = sigmoid(x)) y retorna el resultado de la derivada de la función sigmoide para el y dado: y*(1-y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDMkouAabg_t"
      },
      "outputs": [],
      "source": [
        "def d_sigmoid(y):\n",
        "  return y * (1 - y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnfH9hrTYw82"
      },
      "source": [
        "3. Función `tanh(x)` que recibe un número x y retorna el resultado de la función tangente hiperbólico para dicho `x: (e^x - e^(-x))/(e^x + e^(-x))`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "des8zb9AYw82"
      },
      "outputs": [],
      "source": [
        "def tanh(x):\n",
        "  return (math.exp(x) - math.exp(-x))/(math.exp(x) + math.exp(-x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z1ee3m8Yw82"
      },
      "source": [
        "4. Función `d_tanh(y)` que recibe un número y (tal que `y = tanh(x)`) y retorna el resultado de la derivada de la función tangente hiperbólico para el `y` dado: `1 - y^2`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OK01MHU4Yw83"
      },
      "outputs": [],
      "source": [
        "def d_tanh(y):\n",
        "  return 1-y**2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZCXSZ1VYw83"
      },
      "source": [
        "5. Función `relu(x)` que recibe un número x y retorna el resultado de la función lineal rectificada para dicho `x: (x if x > 0 else 0)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qaUkgxhYw83"
      },
      "outputs": [],
      "source": [
        "def relu(x):\n",
        "  return x if x > 0 else 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9xa3XwYYw84"
      },
      "source": [
        "6. Función `d_relu(y)` que recibe un número `y` (tal que `y = relu(x)`) y retorna el resultado de la derivada de la función lineal rectificada para el y dado: `1 if y >0 else 0`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EPGLc9lYw84"
      },
      "outputs": [],
      "source": [
        "def d_relu(y):\n",
        "  return 1 if y > 0 else 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v29u907lYw85"
      },
      "source": [
        "7. `Función lrelu(x)` que recibe un número x y retorna el resultado de la función lineal rectificada con fuga para dicho x: (x if x>0 else 0.01x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpnfjckGYw86"
      },
      "outputs": [],
      "source": [
        "def lrelu(x):\n",
        "  return x if x>0 else 0.01*x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Jte2MmtYw86"
      },
      "source": [
        "8. Función `d_lrelu(y)` que recibe un número y (tal que y = lrelu(x)) y retorna el resultado de la derivada de la función lineal rectificada con fuga para el y dado: 1 if y>0 else 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuTZlv9fYw86"
      },
      "outputs": [],
      "source": [
        "def d_lrelu(y):\n",
        "  return 1 if y>0 else 0.01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzUsUYKfYw86"
      },
      "source": [
        "`Clase DenseNN`\n",
        "\n",
        "\n",
        "10. `Método predict(self, x)` que recibe una matriz de datos x de tamaño nxm, donde m coincide con el primer valor de layers al construir la red neuronal. Este método ejecuta el forward propagation aplicando la multiplicación con la matrices de pesos y las funciones de activación de cada capa. Finalmente, retorna una matriz de datos nxp, donde p coincide con el último de layers y corresponde a los valores predichos por la red neuronal para los casos x."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UrHMF-hYw87"
      },
      "outputs": [],
      "source": [
        "class DenseNN:\n",
        "    def __init__(self, layers, activation, seed = 0):\n",
        "      np.random.seed(seed)\n",
        "\n",
        "      self.x_count = layers[0]\n",
        "      self.y_count = layers[-1]\n",
        "      self.activation = activation\n",
        "      self.epoch = 0\n",
        "      self.momentum = 0\n",
        "      self.lr = 0\n",
        "      self.decay = 0\n",
        "\n",
        "      self.weight_matrixs = []\n",
        "      self.delta_weight_matrix = []\n",
        "      \n",
        "      self.net_values = []\n",
        "      self.activation_values = []\n",
        "      self.layers_errors = []\n",
        "\n",
        "      # inicialización de la matriz de pesos y bias\n",
        "      for index in range(len(layers[1:])):\n",
        "        fan_in = layers[index] # capa anterior (cantidad de columnas)\n",
        "        fan_out = 0 if len(layers[1:-1]) < index + 1 else layers[index+2] # capa siguiente\n",
        "        self.weight_matrixs.append(np.random.normal(loc = 0, scale=2.0/math.sqrt(fan_in + fan_out), size = (fan_in + 1, layers[index + 1])))\n",
        "\n",
        "    def predict(self, x = pd.DataFrame):\n",
        "      x = x.assign(bias = np.ones(x.shape[0]))\n",
        "      predictions = np.array([])\n",
        "      for index, row in x.iterrows():\n",
        "        # llamada al forward propagation para la fila\n",
        "        predictions = np.append(predictions, self._fowardPropagation(row))\n",
        "      return predictions \n",
        "\n",
        "    def train(self, lr=0.05, momentum=0, decay=0):\n",
        "      self.epoch = 0\n",
        "      # REVISAR\n",
        "      self.delta_weight_mat rix = [[[0]*len(self.weight_matrixs[0][0])]*len(self.weight_matrixs[0])]*len(self.weight_matrixs)\n",
        "      self.lr = lr\n",
        "      self.momentum = momentum\n",
        "      self.decay = decay\n",
        "\n",
        "    def _fowardPropagation(self, row):\n",
        "      # limpieza de los valores netos, activación y error\n",
        "      self.activation_values = []\n",
        "      self.net_values = []\n",
        "      self.layers_errors = []\n",
        "      # inicialización de los valores para la primer capa oculta\n",
        "      net_k = np.matmul(np.transpose(row.to_numpy()), self.weight_matrixs[0])\n",
        "      o_k = self._getActivationValue(0, net_k)\n",
        "      \n",
        "      self.net_values.append(net_k)\n",
        "      \n",
        "      # recorrido desde la segunda capa oculta hasta la salida\n",
        "      for weight_index in range(len(self.weight_matrixs[1:])):\n",
        "        # aplicación de la multiplicación: x*w\n",
        "        net_k = np.matmul(np.transpose(np.append(o_k, 1)), self.weight_matrixs[weight_index + 1])\n",
        "        # Aplicación de la función de activación en cada uno de los resultados\n",
        "        o_k = self._getActivationValue(weight_index + 1, net_k)\n",
        "        self.net_values.append(net_k)\n",
        "        self.activation_values.append(o_k)\n",
        "      return o_k\n",
        "\n",
        "    def backPropagation(self, x, y):\n",
        "      x = x.assign(bias = np.ones(x.shape[0]))\n",
        "      for index, row in x.iterrows():\n",
        "        y_predict = self._fowardPropagation(row)\n",
        "        y_true = y.loc[index]\n",
        "        dj = []\n",
        "        for layer_index in reversed(range(len(self.weight_matrixs))):\n",
        "          if layer_index == len(self.weight_matrixs) - 1:\n",
        "            dj = 2 * (y_predict - y_true) * self._getDerivativeActivationValues(layer_index, self.net_values[layer_index])\n",
        "          else:\n",
        "            \n",
        "            dj = (self.weight_matrixs[layer_index+1] @ dj) * np.append(self._getDerivativeActivationValues(layer_index, self.net_values[layer_index]), 1)\n",
        "\n",
        "            # for i in range(len(dj)):\n",
        "            #   sum += self.weight_matrixs[layer_index][i] * self._getDeltaLastLayer()\n",
        "            # dj = sum * self._getDerivativeActivationValues(layer_index, self.net_values[layer_index])\n",
        "            \n",
        "    def step(self):\n",
        "      # apply backpropagation\n",
        "      self.epoch += 1\n",
        "\n",
        "    def _getDeltaLastLayer(self):\n",
        "      \n",
        "      return 0\n",
        "\n",
        "    def _getDeltaHidingLayer(self):\n",
        "      return 0\n",
        "\n",
        "    def _getActivationValue(self, layer_number, values):\n",
        "      return_values = []\n",
        "      for value in np.nditer(values):\n",
        "        return_values.append(self._applyActivation(layer_number, value))\n",
        "      return np.array(return_values)\n",
        "\n",
        "    def _getDerivativeActivationValues(self, layer_number, values):\n",
        "      return_values = []\n",
        "      for value in np.nditer(values):\n",
        "        return_values.append(self._applyActivationDerivative(layer_number, value))\n",
        "      return np.array(return_values)\n",
        "\n",
        "    def _applyActivation(self, layer_number, value):\n",
        "      if self.activation[layer_number] == 's': # aplicar función sigmoide\n",
        "        return sigmoid(value)\n",
        "      elif self.activation[layer_number] == 't': # aplicar función tangente hiperbólico\n",
        "        return tanh(value)\n",
        "      elif self.activation[layer_number] == 'r': # aplicar función relu\n",
        "        return relu(value)\n",
        "      elif self.activation[layer_number] == 'l': # aplicar función leaky relu\n",
        "        return lrelu(value)\n",
        "      return 0\n",
        "\n",
        "    def _applyActivationDerivative(self, layer_number, value):\n",
        "      if self.activation[layer_number] == 's': # aplicar función sigmoide\n",
        "        return d_sigmoid(value)\n",
        "      elif self.activation[layer_number] == 't': # aplicar función tangente hiperbólico\n",
        "        return d_tanh(value)\n",
        "      elif self.activation[layer_number] == 'r': # aplicar función relu\n",
        "        return d_relu(value)\n",
        "      elif self.activation[layer_number] == 'l': # aplicar función leaky relu\n",
        "        return d_lrelu(value)\n",
        "      return 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjuwJrS9olSa",
        "outputId": "d32451ec-4e23-4b0b-eccc-cec37a5a3680"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4, 12)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([0.50849989, 0.46811816, 0.53291155, 0.49838054, 0.50258385,\n",
              "       0.47866953, 0.53295475, 0.49841047])"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# dismunución del dataset para pruebas\n",
        "df_titanic = df_titanic[:4]\n",
        "y = y[:4]\n",
        "\n",
        "print(df_titanic.shape)\n",
        "neural_net = DenseNN([12, 10, 5, 2],['r', 's', 's'], 0)\n",
        "neural_net.predict(df_titanic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeH4MfoMAiR7"
      },
      "outputs": [],
      "source": [
        "neural_net.backPropagation(df_titanic, y)\n",
        "# neural_net.train()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "5db20e6b6544bef3223c6fee36e7cf17f383763e52191370d8bdafdcda1cbf86"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}