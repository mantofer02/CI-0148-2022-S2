{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbh9Ky3uYw8w"
      },
      "source": [
        "# Laboratorio 4 | Machine Learning\n",
        "* Marco Ferraro | B82957\n",
        "* Roy Padilla | B85854"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "BIElRyehYw8y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # procesamiento de dataset\n",
        "import math # uso de función exp\n",
        "import numpy as np # uso de funciones y generación de arreglos\n",
        "import math # operación de raíz cuadrada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIojcHgKA8XJ",
        "outputId": "f1d97f2c-ea0d-46d3-b8ec-9e023cda219e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1043, 12)"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_value_titanic = ['Survived_0', 'Survived_1']\n",
        "df_titanic = pd.read_csv('titanic.csv')\n",
        "df_titanic = df_titanic.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin']).dropna()\n",
        "\n",
        "# Se pasan a one-hot encoding las columnas 'Pclass','Sex' y 'Survived'\n",
        "df_titanic = pd.get_dummies(df_titanic,columns=['Embarked', 'Pclass','Sex', 'Survived'])\n",
        "y = df_titanic.loc[:, target_value_titanic]\n",
        "\n",
        "\n",
        "df_titanic = df_titanic.drop(columns = target_value_titanic)\n",
        "\n",
        "df_titanic.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p2NcJwCbQXb"
      },
      "source": [
        "1. Función `sigmoid(x)` que recibe un número `x` y retorna el resultado de la función sigmoide para dicho `x:   1/(1 + e^(-x))`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "tZw1OSmmbVeA"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + math.exp(-x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpO9tpHddsST"
      },
      "source": [
        "2. Función d_sigmoid(y) que recibe un número y (tal que y = sigmoid(x)) y retorna el resultado de la derivada de la función sigmoide para el y dado: y*(1-y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "nDMkouAabg_t"
      },
      "outputs": [],
      "source": [
        "def d_sigmoid(y):\n",
        "  return y * (1 - y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnfH9hrTYw82"
      },
      "source": [
        "3. Función `tanh(x)` que recibe un número x y retorna el resultado de la función tangente hiperbólico para dicho `x: (e^x - e^(-x))/(e^x + e^(-x))`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "des8zb9AYw82"
      },
      "outputs": [],
      "source": [
        "def tanh(x):\n",
        "  return (math.exp(x) - math.exp(-x))/(math.exp(x) + math.exp(-x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z1ee3m8Yw82"
      },
      "source": [
        "4. Función `d_tanh(y)` que recibe un número y (tal que `y = tanh(x)`) y retorna el resultado de la derivada de la función tangente hiperbólico para el `y` dado: `1 - y^2`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "OK01MHU4Yw83"
      },
      "outputs": [],
      "source": [
        "def d_tanh(y):\n",
        "  return 1-y**2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZCXSZ1VYw83"
      },
      "source": [
        "5. Función `relu(x)` que recibe un número x y retorna el resultado de la función lineal rectificada para dicho `x: (x if x > 0 else 0)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "2qaUkgxhYw83"
      },
      "outputs": [],
      "source": [
        "def relu(x):\n",
        "  return x if x > 0 else 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9xa3XwYYw84"
      },
      "source": [
        "6. Función `d_relu(y)` que recibe un número `y` (tal que `y = relu(x)`) y retorna el resultado de la derivada de la función lineal rectificada para el y dado: `1 if y >0 else 0`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "5EPGLc9lYw84"
      },
      "outputs": [],
      "source": [
        "def d_relu(y):\n",
        "  return 1 if y > 0 else 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v29u907lYw85"
      },
      "source": [
        "7. `Función lrelu(x)` que recibe un número x y retorna el resultado de la función lineal rectificada con fuga para dicho x: (x if x>0 else 0.01x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "VpnfjckGYw86"
      },
      "outputs": [],
      "source": [
        "def lrelu(x):\n",
        "  return x if x>0 else 0.01*x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Jte2MmtYw86"
      },
      "source": [
        "8. Función `d_lrelu(y)` que recibe un número y (tal que y = lrelu(x)) y retorna el resultado de la derivada de la función lineal rectificada con fuga para el y dado: 1 if y>0 else 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "fuTZlv9fYw86"
      },
      "outputs": [],
      "source": [
        "def d_lrelu(y):\n",
        "  return 1 if y>0 else 0.01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzUsUYKfYw86"
      },
      "source": [
        "`Clase DenseNN`\n",
        "\n",
        "\n",
        "10. `Método predict(self, x)` que recibe una matriz de datos x de tamaño nxm, donde m coincide con el primer valor de layers al construir la red neuronal. Este método ejecuta el forward propagation aplicando la multiplicación con la matrices de pesos y las funciones de activación de cada capa. Finalmente, retorna una matriz de datos nxp, donde p coincide con el último de layers y corresponde a los valores predichos por la red neuronal para los casos x."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "7UrHMF-hYw87"
      },
      "outputs": [],
      "source": [
        "class DenseNN:\n",
        "    def __init__(self, layers, activation, seed = 0):\n",
        "      np.random.seed(seed)\n",
        "\n",
        "      self.x_count = layers[0]\n",
        "      self.y_count = layers[-1]\n",
        "      self.activation = activation\n",
        "      self.epoch = 0\n",
        "      self.momentum = 0\n",
        "      self.lr = 0\n",
        "      self.decay = 0\n",
        "\n",
        "      self.weight_matrixs = []\n",
        "      self.delta_weight_matrix = []\n",
        "      \n",
        "      self.net_values = []\n",
        "      self.activation_values = []\n",
        "      self.layers_errors = []\n",
        "\n",
        "      # inicialización de la matriz de pesos y bias\n",
        "      for index in range(len(layers[1:])):\n",
        "        fan_in = layers[index] # capa anterior (cantidad de columnas)\n",
        "        fan_out = 0 if len(layers[1:-1]) < index + 1 else layers[index+2] # capa siguiente\n",
        "        self.weight_matrixs.append(np.random.normal(loc = 0, scale=2.0/math.sqrt(fan_in + fan_out), size = (fan_in + 1, layers[index + 1])))\n",
        "\n",
        "    def predict(self, x = pd.DataFrame):\n",
        "      x = x.assign(bias = np.ones(x.shape[0]))\n",
        "      predictions = np.array([])\n",
        "      for index, row in x.iterrows():\n",
        "        # llamada al forward propagation para la fila\n",
        "        predictions = np.append(predictions, self._fowardPropagation(row))\n",
        "      return predictions \n",
        "\n",
        "    def train(self, lr=0.05, momentum=0, decay=0):\n",
        "      self.epoch = 0\n",
        "      # REVISAR\n",
        "      self.lr = lr\n",
        "      self.momentum = momentum\n",
        "      self.decay = decay\n",
        "      self.delta_weight_matrix = []\n",
        "      for weight_matrix in self.weight_matrixs:\n",
        "        n_row =  len(weight_matrix)\n",
        "        n_col = len(weight_matrix[0])\n",
        "        self.delta_weight_matrix.append(np.zeros((n_row, n_col)))\n",
        "\n",
        "    def _fowardPropagation(self, row):\n",
        "      # limpieza de los valores netos, activación y error\n",
        "      self.activation_values = []\n",
        "      self.net_values = []\n",
        "      self.layers_errors = []\n",
        "      # inicialización de los valores para la primer capa oculta\n",
        "      net_k = np.matmul(np.transpose(row.to_numpy()), self.weight_matrixs[0])\n",
        "      o_k = self._getActivationValue(0, net_k)\n",
        "      \n",
        "      self.net_values.append(net_k)\n",
        "      \n",
        "      # recorrido desde la segunda capa oculta hasta la salida\n",
        "      for weight_index in range(len(self.weight_matrixs[1:])):\n",
        "        # aplicación de la multiplicación: x*w\n",
        "        net_k = np.matmul(np.transpose(np.append(o_k, 1)), self.weight_matrixs[weight_index + 1])\n",
        "        # Aplicación de la función de activación en cada uno de los resultados\n",
        "        o_k = self._getActivationValue(weight_index + 1, net_k)\n",
        "        self.net_values.append(net_k)\n",
        "        self.activation_values.append(o_k)\n",
        "      return o_k\n",
        "\n",
        "    def backPropagation(self, x, y):\n",
        "      x = x.assign(bias = np.ones(x.shape[0]))\n",
        "      for index, row in x.iterrows():\n",
        "        y_predict = self._fowardPropagation(row)\n",
        "        y_true = y.loc[index]\n",
        "        dj = []\n",
        "        for layer_index in reversed(range(len(self.weight_matrixs))):\n",
        "          if layer_index == len(self.weight_matrixs) - 1:\n",
        "            dj = 2 * (y_predict - y_true) * self._getDerivativeActivationValues(layer_index, self.net_values[layer_index])\n",
        "            oj = self._getActivationValue(layer_index, self.net_values[layer_index])\n",
        "\n",
        "          elif layer_index == 0:\n",
        "            dj = (self.weight_matrixs[layer_index + 1] @ dj) * np.append(self._getDerivativeActivationValues(layer_index, self.net_values[layer_index]), 1)\n",
        "            oj = self.net_values[layer_index]\n",
        "\n",
        "          else:\n",
        "            dj = (self.weight_matrixs[layer_index + 1] @ dj) * np.append(self._getDerivativeActivationValues(layer_index, self.net_values[layer_index]), 1)\n",
        "            oj = self._getActivationValue(layer_index, self.net_values[layer_index])\n",
        "\n",
        "          print(oj.shape)\n",
        "          print(dj.shape)\n",
        "          self.delta_weight_matrix[layer_index] = oj @ dj\n",
        "\n",
        "            \n",
        "    def step(self):\n",
        "      # apply backpropagation\n",
        "      self.epoch += 1\n",
        "\n",
        "    def _getDeltaLastLayer(self):\n",
        "      # se esta haciendo directamente en el for\n",
        "      return 0\n",
        "\n",
        "    def _getDeltaHidingLayer(self):\n",
        "      # se esta aplicando directamente en el for\n",
        "      return 0\n",
        "\n",
        "    def _getActivationValue(self, layer_number, values):\n",
        "      return_values = []\n",
        "      for value in np.nditer(values):\n",
        "        return_values.append(self._applyActivation(layer_number, value))\n",
        "      return np.array(return_values)\n",
        "\n",
        "    def _getDerivativeActivationValues(self, layer_number, values):\n",
        "      return_values = []\n",
        "      for value in np.nditer(values):\n",
        "        return_values.append(self._applyActivationDerivative(layer_number, value))\n",
        "      return np.array(return_values)\n",
        "\n",
        "    def _applyActivation(self, layer_number, value):\n",
        "      if self.activation[layer_number] == 's': # aplicar función sigmoide\n",
        "        return sigmoid(value)\n",
        "      elif self.activation[layer_number] == 't': # aplicar función tangente hiperbólico\n",
        "        return tanh(value)\n",
        "      elif self.activation[layer_number] == 'r': # aplicar función relu\n",
        "        return relu(value)\n",
        "      elif self.activation[layer_number] == 'l': # aplicar función leaky relu\n",
        "        return lrelu(value)\n",
        "      return 0\n",
        "\n",
        "    def _applyActivationDerivative(self, layer_number, value):\n",
        "      if self.activation[layer_number] == 's': # aplicar función sigmoide\n",
        "        return d_sigmoid(value)\n",
        "      elif self.activation[layer_number] == 't': # aplicar función tangente hiperbólico\n",
        "        return d_tanh(value)\n",
        "      elif self.activation[layer_number] == 'r': # aplicar función relu\n",
        "        return d_relu(value)\n",
        "      elif self.activation[layer_number] == 'l': # aplicar función leaky relu\n",
        "        return d_lrelu(value)\n",
        "      return 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjuwJrS9olSa",
        "outputId": "d32451ec-4e23-4b0b-eccc-cec37a5a3680"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4, 12)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[array([[ 0.85569108,  0.19410476,  0.47475766,  1.08699287,  0.90589869,\n",
              "         -0.4740494 ,  0.46086058, -0.07341903, -0.0500685 ,  0.19916953],\n",
              "        [ 0.0698714 ,  0.70542627,  0.36915752,  0.05902105,  0.21530529,\n",
              "          0.16185582,  0.7247348 , -0.09951638,  0.15186014, -0.41429729],\n",
              "        [-1.23838196,  0.31705159,  0.41931315, -0.36000291,  1.10099271,\n",
              "         -0.70547098,  0.02219614, -0.0907975 ,  0.74350713,  0.7127437 ],\n",
              "        [ 0.07516054,  0.18343577, -0.43063934, -0.96082742, -0.16876218,\n",
              "          0.07584039,  0.59677864,  0.5832399 , -0.1878811 , -0.14663837],\n",
              "        [-0.5086229 , -0.68880988, -0.82766261,  0.94626506, -0.24721762,\n",
              "         -0.21249725, -0.60769501,  0.37713822, -0.78285545, -0.10319419],\n",
              "        [-0.43436508,  0.18767528, -0.24777689, -0.57269073, -0.01367039,\n",
              "          0.20777148,  0.03226559,  0.14672042, -0.30769141, -0.17595531],\n",
              "        [-0.32619123, -0.1744089 , -0.39443388, -0.83737006,  0.08606432,\n",
              "         -0.19489238, -0.79076235,  0.22448237, -0.44010435,  0.02519722],\n",
              "        [ 0.35366087,  0.0625659 ,  0.55269051, -0.5989785 ,  0.19516436,\n",
              "         -0.33218169, -0.42239866, -0.28078333, -0.15112518,  0.02724419],\n",
              "        [-0.56518069,  0.43696503,  0.22587946, -0.74518765,  0.72190835,\n",
              "          0.91964133,  0.57179208, -0.08727637, -0.51939131,  0.51148422],\n",
              "        [-0.19556955,  0.59297296,  0.1010282 ,  0.47373952,  0.17286309,\n",
              "          0.34273833,  0.00509326,  0.86627443,  0.06156141,  0.19499348],\n",
              "        [ 0.91346226, -0.65375917, -0.61627575,  0.47022647, -0.56904844,\n",
              "          0.94279476, -0.20063468, -0.36256884,  0.93276389,  0.71815516],\n",
              "        [ 0.90589916,  0.43949622, -0.41775582,  0.92651759, -0.13000073,\n",
              "          0.38924853,  0.4594847 , -0.07519094,  0.29787225,  0.44733594],\n",
              "        [ 0.1825932 , -0.53328772,  0.14466676,  0.64339166, -0.3369149 ,\n",
              "         -0.07258341, -0.21108048,  0.89702467,  0.32611086,  0.19764802]]),\n",
              " array([[-0.44451125,  0.31133567, -0.38932614,  0.01837738, -0.3671059 ],\n",
              "        [ 0.39053894,  0.33289486, -0.12026134,  0.22863458, -0.63107936],\n",
              "        [-0.86097797,  0.25368292,  0.09622899,  0.36663557,  1.37590928],\n",
              "        [ 0.54529549, -0.52701816,  0.64490965, -0.7597395 , -0.266496  ],\n",
              "        [-0.03939931,  0.98919888, -0.4299844 , -0.47714451, -0.05684159],\n",
              "        [-0.38305937,  0.65046355, -0.62349875, -0.66249134, -0.25277552],\n",
              "        [-0.28753917,  1.11401585,  0.54814836,  0.05054773, -0.70750553],\n",
              "        [ 0.48749319, -0.5774746 , -0.89187401,  0.68590932,  0.1829869 ],\n",
              "        [ 0.53165809,  0.1840175 ,  0.49469138, -0.3758698 , -0.59712038],\n",
              "        [ 0.39351878, -0.46384879, -0.39811175, -0.26300181,  0.0100916 ],\n",
              "        [-0.20437848, -0.7938285 , -0.37159326, -1.28368241,  0.36097755]]),\n",
              " array([[-1.43292393, -0.98779049],\n",
              "        [ 0.04665787, -0.66148525],\n",
              "        [ 1.38011421, -1.15636637],\n",
              "        [ 0.23885756, -0.03513562],\n",
              "        [-1.04477459,  0.46803287],\n",
              "        [-0.1534357 ,  0.69031045]])]"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# dismunución del dataset para pruebas\n",
        "df_titanic = df_titanic[:4]\n",
        "y = y[:4]\n",
        "\n",
        "print(df_titanic.shape)\n",
        "neural_net = DenseNN([12, 10, 5, 2],['r', 's', 's'], 0)\n",
        "# neural_net.predict(df_titanic)\n",
        "neural_net.weight_matrixs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "BeH4MfoMAiR7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2,)\n",
            "(2,)\n",
            "(5,)\n",
            "(6,)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 6 is different from 5)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [117], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# neural_net.backPropagation(df_titanic, y)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m neural_net\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mneural_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackPropagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_titanic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn [115], line 88\u001b[0m, in \u001b[0;36mDenseNN.backPropagation\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(oj\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(dj\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelta_weight_matrix[layer_index] \u001b[38;5;241m=\u001b[39m \u001b[43moj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdj\u001b[49m\n",
            "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 6 is different from 5)"
          ]
        }
      ],
      "source": [
        "# neural_net.backPropagation(df_titanic, y)\n",
        "neural_net.train()\n",
        "neural_net.backPropagation(df_titanic, y)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.3 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
